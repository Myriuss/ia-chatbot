{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 1800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.11,
      "grad_norm": 0.8544905185699463,
      "learning_rate": 4.8611111111111115e-05,
      "loss": 4.0648,
      "step": 50
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.111141562461853,
      "learning_rate": 4.722222222222222e-05,
      "loss": 3.8995,
      "step": 100
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.5269019603729248,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 3.6778,
      "step": 150
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5130198001861572,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 3.3438,
      "step": 200
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.4771571159362793,
      "learning_rate": 4.305555555555556e-05,
      "loss": 3.2031,
      "step": 250
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.093255043029785,
      "learning_rate": 4.166666666666667e-05,
      "loss": 3.1502,
      "step": 300
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.9085237979888916,
      "learning_rate": 4.027777777777778e-05,
      "loss": 3.0141,
      "step": 350
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.0936853885650635,
      "learning_rate": 3.888888888888889e-05,
      "loss": 2.9709,
      "step": 400
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1666462421417236,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 2.9108,
      "step": 450
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.707228660583496,
      "eval_runtime": 23.6527,
      "eval_samples_per_second": 4.228,
      "eval_steps_per_second": 0.55,
      "step": 450
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.5490317344665527,
      "learning_rate": 3.611111111111111e-05,
      "loss": 2.9262,
      "step": 500
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.390545606613159,
      "learning_rate": 3.472222222222222e-05,
      "loss": 2.9286,
      "step": 550
    },
    {
      "epoch": 1.33,
      "grad_norm": 4.658451080322266,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 2.7358,
      "step": 600
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.5566601753234863,
      "learning_rate": 3.194444444444444e-05,
      "loss": 2.7076,
      "step": 650
    },
    {
      "epoch": 1.56,
      "grad_norm": 3.411797285079956,
      "learning_rate": 3.055555555555556e-05,
      "loss": 2.7116,
      "step": 700
    },
    {
      "epoch": 1.67,
      "grad_norm": 2.9126930236816406,
      "learning_rate": 2.916666666666667e-05,
      "loss": 2.7377,
      "step": 750
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.5020129680633545,
      "learning_rate": 2.777777777777778e-05,
      "loss": 2.6222,
      "step": 800
    },
    {
      "epoch": 1.89,
      "grad_norm": 2.1487598419189453,
      "learning_rate": 2.6388888888888892e-05,
      "loss": 2.6816,
      "step": 850
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.186140298843384,
      "learning_rate": 2.5e-05,
      "loss": 2.6532,
      "step": 900
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.4185757637023926,
      "eval_runtime": 22.5566,
      "eval_samples_per_second": 4.433,
      "eval_steps_per_second": 0.576,
      "step": 900
    },
    {
      "epoch": 2.11,
      "grad_norm": 3.2997820377349854,
      "learning_rate": 2.361111111111111e-05,
      "loss": 2.6117,
      "step": 950
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.4157016277313232,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 2.5325,
      "step": 1000
    },
    {
      "epoch": 2.33,
      "grad_norm": 3.639988422393799,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 2.4839,
      "step": 1050
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.669886350631714,
      "learning_rate": 1.9444444444444445e-05,
      "loss": 2.5272,
      "step": 1100
    },
    {
      "epoch": 2.56,
      "grad_norm": 3.6329872608184814,
      "learning_rate": 1.8055555555555555e-05,
      "loss": 2.5174,
      "step": 1150
    },
    {
      "epoch": 2.67,
      "grad_norm": 3.8794848918914795,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 2.624,
      "step": 1200
    },
    {
      "epoch": 2.78,
      "grad_norm": 3.4742953777313232,
      "learning_rate": 1.527777777777778e-05,
      "loss": 2.5245,
      "step": 1250
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.8460958003997803,
      "learning_rate": 1.388888888888889e-05,
      "loss": 2.6408,
      "step": 1300
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.0866637229919434,
      "learning_rate": 1.25e-05,
      "loss": 2.5203,
      "step": 1350
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.279313087463379,
      "eval_runtime": 22.5348,
      "eval_samples_per_second": 4.438,
      "eval_steps_per_second": 0.577,
      "step": 1350
    },
    {
      "epoch": 3.11,
      "grad_norm": 4.606627464294434,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 2.4466,
      "step": 1400
    },
    {
      "epoch": 3.22,
      "grad_norm": 3.1544151306152344,
      "learning_rate": 9.722222222222223e-06,
      "loss": 2.585,
      "step": 1450
    },
    {
      "epoch": 3.33,
      "grad_norm": 3.9936814308166504,
      "learning_rate": 8.333333333333334e-06,
      "loss": 2.5092,
      "step": 1500
    },
    {
      "epoch": 3.44,
      "grad_norm": 4.19682502746582,
      "learning_rate": 6.944444444444445e-06,
      "loss": 2.5491,
      "step": 1550
    },
    {
      "epoch": 3.56,
      "grad_norm": 2.751328468322754,
      "learning_rate": 5.555555555555556e-06,
      "loss": 2.4187,
      "step": 1600
    },
    {
      "epoch": 3.67,
      "grad_norm": 2.802186965942383,
      "learning_rate": 4.166666666666667e-06,
      "loss": 2.5505,
      "step": 1650
    },
    {
      "epoch": 3.78,
      "grad_norm": 3.808972120285034,
      "learning_rate": 2.777777777777778e-06,
      "loss": 2.4429,
      "step": 1700
    },
    {
      "epoch": 3.89,
      "grad_norm": 3.5084431171417236,
      "learning_rate": 1.388888888888889e-06,
      "loss": 2.3618,
      "step": 1750
    },
    {
      "epoch": 4.0,
      "grad_norm": 4.308132648468018,
      "learning_rate": 0.0,
      "loss": 2.2801,
      "step": 1800
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.2357916831970215,
      "eval_runtime": 23.5731,
      "eval_samples_per_second": 4.242,
      "eval_steps_per_second": 0.551,
      "step": 1800
    }
  ],
  "logging_steps": 50,
  "max_steps": 1800,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 117991224115200.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
